---
title: "p8105_hw3_yz4982"
author: "Yuanyuan Zhang"
output:
  github_document: default
--- 

Promblem 1
------------------------------------------------------------
### Library
```{r}
library(tidyverse)
library(p8105.datasets)
library(forcats) 
library(janitor)
library(lubridate)
library(ggplot2)
library(patchwork)

data("instacart")
```

### Description
```{r}
n_rows <- nrow(instacart)
n_cols <- ncol(instacart)

n_users       <- n_distinct(instacart$user_id)
n_orders      <- n_distinct(instacart$order_id)
n_products    <- n_distinct(instacart$product_id)
n_aisles      <- n_distinct(instacart$aisle)

cat(
  "rows:", n_rows,
  "columns:", n_cols, "\n",
  "unique users:", n_users,
  "unique orders:", n_orders, "\n",
  "unique products:", n_products,
  "unique aisles:", n_aisles, "\n"
)

# check variables and type
# glimpse(instacart)

# key varibles
set.seed(8105)
instacart |> 
  select(order_id, user_id, product_id, product_name, aisle, department, 
         add_to_cart_order, reordered, order_dow, order_hour_of_day) |>
  slice_sample(n = 5)

```

### Number of Aisles
```{r}
# Counting the number of products ordered per aisle
aisle_counts <- instacart |>
  count(aisle, name = "n_items") |>
  arrange(desc(n_items))

# Total aisle 
n_aisles <- nrow(aisle_counts)
n_aisles

# Top 5 most ordered aisles
top_aisles <- aisle_counts |> slice_max(n_items, n = 5)
top_aisles
```

### Plot The Number of Items Ordered in Each Aisle
```{r}
plot_df <- aisle_counts |>
  filter(n_items > 10000) |>
  mutate(aisle = fct_reorder(aisle, n_items))

p <- ggplot(plot_df, aes(x = n_items, y = aisle)) +
  geom_col() +
  labs(
    title = "Number of items ordered by aisle (> 10,000)",
    x = "Items ordered",
    y = "Aisle"
  )

ggplot2::ggsave(
  filename = "Figures/aisle_items_over_10k.png",
  plot = p,
  width = 8, height = 5, units = "in", dpi = 300
)

print (p)
```

### Table of Top 3 Popular Items in Each of The Aisles 
```{r}
top3_tbl <- instacart |>
  # Keep only rows from these three aisles
  filter(aisle %in% c("baking ingredients",
                      "dog food care",
                      "packaged vegetables fruits")) |>
  # Count
  count(aisle, product_name, name = "times_ordered", sort = TRUE) |>
  # Make group
  group_by(aisle) |>
  # Take the top 3 products each aisle
  slice_max(times_ordered, n = 3) |>
  # Order by aisle
  arrange(aisle, desc(times_ordered)) |>
  # Assign ranks
  mutate(rank_in_aisle = row_number()) |>
  select(aisle, rank_in_aisle, product_name, times_ordered) |>
  ungroup()

# Print
top3_tbl
```

### Mean Hour of The Day
```{r}
mean_hour_tbl <- instacart |>
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) |>
  mutate(
    # Instacart encodes convert
    day_convert = factor(order_dow, levels = 0:6,
                 labels = c("Sun","Mon","Tue","Wed","Thu","Fri","Sat"))
  ) |>
  # Make group
  group_by(product_name, day_convert) |>
  # Calculate the mean
  summarise(mean_hour = mean(order_hour_of_day), .groups = "drop") |>
  # Make 2*7 table
  tidyr::pivot_wider(names_from = day_convert, values_from = mean_hour) |>
  rename(Product = product_name)

# Print
mean_hour_tbl
```

Promblem 2
------------------------------------------------------------
### Import Data
```{r}
zip_code_df = 
  read_csv("p8105_hw3_yz4982_files/zillow_data/Zip Codes.csv", 
           na = c("NA", ".", ""))

# check variables and type
glimpse(zip_code_df)


zori_raw = 
  read_csv("p8105_hw3_yz4982_files/zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv", 
           na = c("NA", ".", ""))

# Check variables and type
# glimpse(zip_code_df)
# glimpse(zori_raw )
```

### Clean Data
```{r}

zori_long <- zori_raw |>
  rename(zip = RegionName) |>
  pivot_longer(
    cols = matches("^\\d{4}-\\d{2}-\\d{2}$"),
    names_to = "month",
    values_to = "zori"
  ) |>
  mutate(month = lubridate::ymd(month)) |>
  # keep only 2015-01-31 to 2024-08-31
  filter(month >= ymd("2015-01-31"),
         month <= ymd("2024-08-31"))
```

### Statisic Calculate
```{r}
zip_month_counts <- zori_long |>
  group_by(zip) |>
  summarise(months_observed = sum(!is.na(zori)), .groups = "drop")

# ZIP codes are observed 116 times
n_exact_116 <- sum(zip_month_counts$months_observed == 116)

# Observed fewer than 10 times
n_fewer_10  <- sum(zip_month_counts$months_observed < 10)

# Print
cat("ZIP codes are observed 116 times：", n_exact_116, "\n")
cat("Observed fewer than 10 times：", n_fewer_10, "\n")
```

Make a table see
```{r}
summary_tbl <- zip_month_counts |>
  mutate(coverage = case_when(
    months_observed == 116 ~ "total 116 month",
    months_observed < 10   ~ "<10 month",
    TRUE                   ~ "partial 10–115 month"
  )) |>
  count(coverage, name = "count zip") |>
  arrange(match(coverage,
                c("total 116 month","<10 month","partial 10–115 month")))

summary_tbl
```
Zillow reports a monthly value only when there are enough valid rental listings; otherwise the month is NA. ZIPs with active residential markets therefore show values in all 116 months.Non-residential or special-use ZIPs and places with very few listings are often missing many months.Occasional gaps also come from boundary changes.

### Reader-friendly Table 
```{r}
# ZIP to Borough
borough_xwalk <- data.frame(
  County  = c("New York","Kings","Queens","Bronx","Richmond"),
  borough = c("Manhattan","Brooklyn","Queens","Bronx","Staten Island"),
  stringsAsFactors = FALSE
)

zip_to_borough <- zip_code_df |>
  select(ZipCode, County) |>
  left_join(borough_xwalk, by = "County") |>
  transmute(zip = as.integer(ZipCode), borough)

# Take the average of the ZIPs within the borough-year.
borough_year <- zori_long |>
  mutate(zip = as.integer(zip),
         year = year(month)) |>
  inner_join(zip_to_borough, by = "zip") |>
  group_by(borough, zip, year) |>
  summarise(zip_year_mean = mean(zori, na.rm = TRUE), .groups = "drop") |>
  group_by(borough, year) |>
  summarise(avg_rent = round(mean(zip_year_mean, na.rm = TRUE)), .groups = "drop")

# Make Table
table_wide <- borough_year |>
  arrange(borough, year) |>
  pivot_wider(names_from = year, values_from = avg_rent)

# Print
print(table_wide)

```

### Plot Showing NYC Rental Prices
```{r}
# ZIP annual mean
zip_year <- zori_long |>
  mutate(zip = as.integer(zip),
         year = lubridate::year(month)) |>
  inner_join(zip_to_borough, by = "zip") |>
  group_by(borough, zip, year) |>
  summarise(zip_year_mean = mean(zori, na.rm = TRUE), .groups = "drop")

# Borough median
borough_year_median <- zip_year |>
  group_by(borough, year) |>
  summarise(median_rent = median(zip_year_mean, na.rm = TRUE), .groups = "drop")


# Plot thin lines with ZIPs, thick line is borough median
ggplot(zip_year, aes(x = year, y = zip_year_mean, group = zip)) +
  geom_line(alpha = 0.3) +
  geom_line(data = borough_year_median,
            aes(y = median_rent, group = NULL),
            linewidth = 1) +
  facet_wrap(~ borough, ncol = 2) +
  labs(
    title = "NYC Rental Prices by ZIP Annual Means",
    x = "Year",
    y = "Average ZORI"
  )

```
For the full period, Manhattan is the highest, Staten Island is the lowest, Brooklyn/Queens is in the middle, and the Bronx is lower than Brooklyn/Queens but has risen rapidly in recent years. The distribution of ZIP prices is more spread out in Manhattan and Brooklyn, suggesting greater variation, and tighter in the Bronx and Staten Island, suggesting less variation. The ZIP price distribution is more spread out in Manhattan and Brooklyn, suggesting large differences, and tighter in Bronx and Staten Island, suggesting small differences).

### Plot of ZIP-code-level rental prices across boroughs in 2023
```{r}
# Filter 2023 year calculate mean
zip_2023 <- zori_long |>
  mutate(year = year(month), zip = as.integer(zip)) |>
  filter(year == 2023) |>
  inner_join(zip_to_borough, by = "zip") |>
  group_by(borough, zip) |>
  summarise(zip_mean_2023 = mean(zori, na.rm = TRUE), .groups = "drop") |>
  filter(is.finite(zip_mean_2023))  # 去掉全年都缺失的 ZIP

# Create box plot
ggplot(zip_2023, aes(x = borough, y = zip_mean_2023)) +
  geom_boxplot(outlier.alpha = 0.3) +
  geom_jitter(width = 0.1, alpha = 0.2) +
  labs(
    title = "Distribution of ZIP-level Average Rental Prices by Borough in 2023",
    x = "Borough",
    y = "Average ZORI in 2023"
  )
```
For median, Manhattan is the highest and Staten Island is the lowest; Brooklyn and Queens is in the middle and Bronx is slightly lower. Manhattan and Brooklyn have longer box and more dispersed scatter, suggesting greater variation among ZIPs, Bronx and Staten Island are more centralized.

```{r}
p1 <- ggplot(zip_year, aes(x = year, y = zip_year_mean, group = zip)) +
  geom_line(alpha = 0.3) +
  geom_line(data = borough_year_median,
            aes(y = median_rent, group = NULL),
            linewidth = 1) +
  facet_wrap(~ borough, ncol = 2) +
  labs(
    title = "NYC Rental Prices by ZIP Annual Means",
    x = "Year",
    y = "Average ZORI"
  )

p2 <- ggplot(zip_2023, aes(x = borough, y = zip_mean_2023)) +
  geom_boxplot(outlier.alpha = 0.3) +
  geom_jitter(width = 0.1, alpha = 0.2) +
  labs(
    title = "Distribution of ZIP-level Average Rental Prices by Borough in 2023",
    x = "Borough",
    y = "Average ZORI in 2023"
  )

# Combine
combined <- p1 / p2
ggplot2::ggsave("Figures/nyc_rental_prices_combined.png", combined, width = 10, height = 10, dpi = 300)
combined 
```

Promblem 3
------------------------------------------------------------
### Data Clean
```{r}
# Import data
covar_raw <- read.csv("p8105_hw3_yz4982_files/nhanes_covar.csv",
                      header = FALSE,
                      stringsAsFactors = FALSE,
                      na.strings = c("", "NA", "."))

# Find the true header row
hdr_row <- which(covar_raw[, 1] == "SEQN")[1]

# Set that row as column names
names(covar_raw) <- as.character(covar_raw[hdr_row, ])
covar <- covar_raw[(hdr_row + 1):nrow(covar_raw), ]

# Set that row as column names; keep only the rows below it as data.
row.names(covar) <- NULL

## Convert ID BMI and age to integer
covar$SEQN <- as.integer(covar$SEQN)
covar$age  <- as.integer(covar$age)
covar$BMI <- as.numeric(covar$BMI)

# Encode factors with readable labels
covar$sex <- factor(covar$sex, levels = c("1","2"), labels = c("Male","Female"))
covar$education <- factor(covar$education,
                          levels = c("1","2","3"),
                          labels = c("Less than high school",
                                     "High school equivalent",
                                     "More than high school"),
                          ordered = TRUE)

# Keep participants match condition
covar <- covar[!is.na(covar$sex) & !is.na(covar$age) & !is.na(covar$education) & covar$age >= 21, ]

# Import accelerometer data and reshape to long
accel <- read.csv("p8105_hw3_yz4982_files/nhanes_accel.csv", stringsAsFactors = FALSE)
mcols <- grep("^min\\d+$", names(accel), value = TRUE)           # min1..min1440
mins  <- as.integer(sub("^min", "", mcols))

accel_long <- data.frame(
  SEQN   = rep(accel$SEQN, each = length(mcols)),
  minute = rep(mins, times = nrow(accel)),
  MIMS   = as.numeric(unlist(accel[mcols], use.names = FALSE))
)
accel_long$SEQN  <- as.integer(accel_long$SEQN)
accel_long$minute <- as.integer(accel_long$minute)

# Combine data
data3 <- merge(covar, accel_long, by = "SEQN")
data3 <- data3[order(data3$SEQN, data3$minute), ]
row.names(data3) <- NULL

# Check
head(data3); class(data3)   
length(unique(data3$SEQN))
range(data3$minute)

```

```{r}

```
